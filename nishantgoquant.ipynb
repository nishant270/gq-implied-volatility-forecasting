{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "041966af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-13T16:44:39.621726Z",
     "iopub.status.busy": "2025-08-13T16:44:39.621221Z",
     "iopub.status.idle": "2025-08-13T16:45:10.772805Z",
     "shell.execute_reply": "2025-08-13T16:45:10.771953Z"
    },
    "executionInfo": {
     "elapsed": 10153,
     "status": "ok",
     "timestamp": 1755094724153,
     "user": {
      "displayName": "Nishant Prasad",
      "userId": "12461116011594648579"
     },
     "user_tz": -330
    },
    "id": "fcf2e1d7",
    "outputId": "584e0834-d1f1-43c6-8af4-b9f2df606e5d",
    "papermill": {
     "duration": 31.156583,
     "end_time": "2025-08-13T16:45:10.775390",
     "exception": false,
     "start_time": "2025-08-13T16:44:39.618807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data exists\n",
      "train: (631292, 22)\n",
      "test: (270548, 22)\n",
      "cols: ['mid_price', 'bid_price1', 'bid_volume1', 'bid_price2', 'bid_volume2', 'bid_price3', 'bid_volume3', 'bid_price4', 'bid_volume4', 'bid_price5', 'bid_volume5', 'ask_price1', 'ask_volume1', 'ask_price2', 'ask_volume2', 'ask_price3', 'ask_volume3', 'ask_price4', 'ask_volume4', 'ask_price5', 'ask_volume5', 'bid_ask_spread']\n",
      "train lgbm...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5388\n",
      "[LightGBM] [Info] Number of data points in the train set: 631292, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 0.000062\n",
      "done\n",
      "sub saved: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# check env -> set path\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    DATA_PATH = \"/kaggle/input/gq-implied-volatility-forecasting\"\n",
    "    print(\"data exists\")\n",
    "else:\n",
    "    DATA_PATH = \"/content/gq-implied-volatility-forecasting\"  # change if diff\n",
    "    print(\"local/colab mode\")\n",
    "\n",
    "# --- load + prep data ---\n",
    "def load_data():\n",
    "    # read csv\n",
    "    tr = pd.read_csv(f\"{DATA_PATH}/train/ETH.csv\")\n",
    "    ts = pd.read_csv(f\"{DATA_PATH}/test/ETH.csv\")\n",
    "    sub = pd.read_csv(f\"{DATA_PATH}/submission.csv\")\n",
    "\n",
    "    # new col: spread\n",
    "    tr[\"bid_ask_spread\"] = tr[\"ask_price1\"] - tr[\"bid_price1\"]\n",
    "    ts[\"bid_ask_spread\"] = ts[\"ask_price1\"] - ts[\"bid_price1\"]\n",
    "\n",
    "    # only keep features (no time, no label)\n",
    "    feats = [c for c in tr.columns if c not in [\"timestamp\", \"label\"]]\n",
    "    tgt = \"label\"\n",
    "\n",
    "    return tr[feats], tr[tgt], ts[feats], sub\n",
    "\n",
    "X_train, y_train, X_test, sub_df = load_data()\n",
    "\n",
    "print(\"train:\", X_train.shape)\n",
    "print(\"test:\", X_test.shape)\n",
    "print(\"cols:\", X_train.columns.tolist())\n",
    "\n",
    "# --- train model ---\n",
    "print(\"train lgbm...\")\n",
    "lgbm = LGBMRegressor(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=-1,\n",
    "    num_leaves=64,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm.fit(X_train, y_train)\n",
    "print(\"done\")\n",
    "\n",
    "# --- predict ---\n",
    "preds = lgbm.predict(X_test)\n",
    "\n",
    "# # --- rmse ---\n",
    "# train_preds = lgbm.predict(X_train)\n",
    "# rmse = mean_squared_error(y_train, train_preds, squared=False)\n",
    "# print(\"train RMSE:\", rmse)\n",
    "\n",
    "# --- save sub ---\n",
    "sub_df[\"labels\"] = preds\n",
    "sub_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "print(\"sub saved: submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyP107UiF9wuF1t3HyS8zsin",
   "gpuType": "T4",
   "mount_file_id": "1KeBEP1EHARM3g5mlaReqb1KSroQkunl6",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13345061,
     "sourceId": 108376,
     "sourceType": "competition"
    },
    {
     "sourceId": 254936003,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 35.856146,
   "end_time": "2025-08-13T16:45:11.394964",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-13T16:44:35.538818",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
